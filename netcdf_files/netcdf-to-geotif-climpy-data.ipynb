{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climpy data\n",
    "- Reading a NetCDF file, analyzing the internals and finally extract the dessired layer into new files (under development)\n",
    "- WIth GDAL, extracting the bands one by one into new files (finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    CDI: Climate Data Interface version 1.9.9rc1 (https://mpimet.mpg.de/cdi)\n",
      "    Conventions: CF-1.6\n",
      "    history: Tue Dec 21 15:29:10 2021: cdo setmissval,-999 climpy_rain_amount_d_def.nc climpy_rain_amount_corrected.nc\n",
      "Thu Dec 02 11:56:40 2021: cdo divc,10 climpy_rain_amount_df.nc climpy_rain_amount_d.nc\n",
      "Thu Dec 02 10:58:18 2021: cdo setmissval,-999 climpy_rain_amount_def.nc climpy_rain_amount_df.nc\n",
      "Wed Dec 01 14:11:24 2021: cdo divc,10 climpy_rain_amount_c.nc climpy_rain_amount_def.nc\n",
      "Fri Nov 26 09:47:43 2021: cdo setmissval,-999 climpy_rain_amount.nc climpy_rain_amount_c.nc\n",
      "    CDO: Climate Data Operators version 1.9.9rc1 (https://mpimet.mpg.de/cdo)\n",
      "    dimensions(sizes): time(252), lon(553), lat(214)\n",
      "    variables(dimensions): float64 \u001b[4mtime\u001b[0m(time), float64 \u001b[4mlon\u001b[0m(lon), float64 \u001b[4mlat\u001b[0m(lat), float64 \u001b[4mrain_amount\u001b[0m(time,lat,lon)\n",
      "    groups: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\.conda\\envs\\gdal_env\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"Open the file and see what it is inside\"\"\"\n",
    "try: fn.close()  # just to be safe, make sure dataset is not already open.\n",
    "except: pass\n",
    "\n",
    "# fn = r\"//akif.internal/public/demo-geo-stack/geoserver/data/climpy_data/netcdf_examples/temperatura_superficial_agua_mar_cambios_sst_mediterraneo_rcp85_2081_2100.nc\"\n",
    "fn = r\"//akif.internal/public/demo-geo-stack/geoserver/data/climpy_data/aries_mendia_climpy/climpy_rain_amount_corrected_copy.nc\"\n",
    "ds = nc.Dataset(fn, mode='r+') #, mode='w',format='NETCDF4'\n",
    "# Here we print the characteristics\n",
    "print(ds)\n",
    "# here we print the characteristics as a dictionary\n",
    "# print(ds.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 252\n",
      "\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 553\n",
      "\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 214\n",
      "\n",
      "odict_keys(['time', 'lon', 'lat', 'rain_amount'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\gdal\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Here we check the dimensions: we get the three values, time, latitud and longitude\"\"\"\n",
    "#longitude and latitute define the size of the layers. Time defines the number of layers inside \n",
    "for dim in ds.dimensions.values():\n",
    "    print(dim) #it is no possible to iterate the dimension\n",
    "\n",
    "\"\"\"Check variables\"\"\"\n",
    "print (ds.variables.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days since 1981-01-31\n",
      "proleptic_gregorian\n",
      "('time',)\n",
      "[5113. 5141. 5172.]\n",
      "1995-01-31 00:00:00\n",
      "1995_01_31\n",
      "1995-02-28 00:00:00\n",
      "1995_02_28\n",
      "1995-03-31 00:00:00\n",
      "1995_03_31\n",
      "[cftime.DatetimeGregorian(1995, 1, 31, 0, 0, 0, 0, has_year_zero=False)\n",
      " cftime.DatetimeGregorian(1995, 2, 28, 0, 0, 0, 0, has_year_zero=False)\n",
      " cftime.DatetimeGregorian(1995, 3, 31, 0, 0, 0, 0, has_year_zero=False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\gdal\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\admin\\.conda\\envs\\gdal\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  \"\"\"\n",
      "C:\\Users\\admin\\.conda\\envs\\gdal\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"This is some testing. We want to get the time variable. So we are going to transform the values into an array\"\"\"\n",
    "time_variable = ds.variables['time'] #we get the time variable\n",
    "\"\"\"if we try to change the time variable, the rest of the data wil change too\"\"\"\n",
    "# time_variable.units = \"days since 1995-1-30\"\n",
    "print(time_variable.units) #here we get from which date it starts, the data officially starts at 1995, not at 1950. The content of this info may be edited by someone else.\n",
    "print(time_variable.calendar)\n",
    "print(time_variable.dimensions) # Here we get the dimensions in the variables\n",
    "\n",
    "time_array = time_variable[:] #we get the array\n",
    "print(time_array[0:3])\n",
    "time_test = nc.num2date(time_array[0:3],\"days since 1981-1-31\")\n",
    "for j in time_test:\n",
    "    print(str(j))\n",
    "    j_test = \"_\".join([str(s) for s in str(j).replace(\"-\",\" \").split() if s.isdigit()]) #get the date without the hh:mm:SS\n",
    "    print(j_test)\n",
    "print(time_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to read a certain part of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.parser\n",
    "\n",
    "#concept of bands: https://stackoverflow.com/questions/52046282/convert-netcdf-nc-to-geotiff\n",
    "sdt = dateutil.parser.parse(\"2015-07-20T00:00:00\")\n",
    "edt = dateutil.parser.parse(\"2015-07-24T00:00:00\")\n",
    "\n",
    "st_idx = nc.date2index(sdt, time_variable)\n",
    "et_idx = nc.date2index(edt, time_variable)\n",
    "\n",
    "\"\"\"We already defined the time variable\"\"\"\n",
    "time_array_filtered = time_variable[st_idx:et_idx+1] #I want to read between 2015-07-20 00:00 to 2015-07-24 00:00\n",
    "print(time_array_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here starts the real transformation. Netcdf to Geotif with GDAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import netCDF4 as nc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n",
      "['1995_01_31', '1995_02_28', '1995_03_31']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\gdal\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\admin\\.conda\\envs\\gdal\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Here we get the number of bands and starting date\"\"\"\n",
    "\n",
    "fn = r\"//akif.internal/public/demo-geo-stack/geoserver/data/climpy_data/aries_mendia_climpy/climpy_rain_amount_corrected.nc\"\n",
    "ds = nc.Dataset(fn)\n",
    "\n",
    "\"\"\"Set the dimension\"\"\"\n",
    "dimension = 'time'\n",
    "\n",
    "date_list = []\n",
    "\n",
    "for dim in ds.dimensions.values():\n",
    "    if dim == ds.dimensions[dimension]:\n",
    "        number_bands = len(dim) #number of bands\n",
    "        variable = ds.variables[dimension]\n",
    "        starting_date = variable.units\n",
    "        array = variable[:]\n",
    "        time_format = nc.num2date(array,starting_date)\n",
    "        for date_element in time_format:\n",
    "            # replace \"-\" for \" \" so \"split\" can work, filter and create a list by digits and finally join them in a single string with \"_\" as separator\n",
    "            date_element_formated = \"_\".join([str(s) for s in str(date_element).replace(\"-\",\" \").split() if s.isdigit()])\n",
    "            date_list.append(date_element_formated)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(number_bands)\n",
    "print(date_list[0:3])\n",
    "# print (ds.variables.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Here we create the output folder if it does not exist\"\"\"\n",
    "root_dir = os.path.dirname(fn)\n",
    "output_folder = \"netcdf_output\"\n",
    "output_dir = os.path.join(root_dir, output_folder).replace(\"\\\\\",\"/\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "climpy_rain_amount_corrected_test.nc\n",
      "//akif.internal/public/demo-geo-stack/geoserver/data/climpy_data/aries_mendia_climpy/climpy_rain_amount_corrected_test\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Some tests of naming files\"\"\"\n",
    "file_name = os.path.splitext(fn)[0]\n",
    "print(os.path.basename(fn))\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "climpy_rain_amount_corrected.nc\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Here we start transforming the data\"\"\"\n",
    "gdal.UseExceptions()\n",
    "\n",
    "# file_name = os.path.splitext(fn)[0]\n",
    "print(os.path.basename(fn))\n",
    "file_name = os.path.basename(fn)\n",
    "k = 0\n",
    "for i in date_list: # [0:2] \"for testing\"\n",
    "    k += 1\n",
    "    output = output_dir + \"/\" + file_name.replace(\".nc\",\"\") + \"_\" + i + \".tif\"\n",
    "    \"\"\"Method1\"\"\"\n",
    "    # gdal.Translate(output, fn, \n",
    "    #                 format='GTIFF',\n",
    "    #                 # format='NetCDF',\n",
    "    #                 # bandList = [1]\n",
    "    #                 # creationOptions = ['COMPRESS=DEFLATE','TILED=YES']\n",
    "    #                 )\n",
    "    \"\"\"Method2\"\"\"\n",
    "    gdaltranString = \"gdal_translate -of GTiff -a_srs epsg:4326 -b \" + str(k) + \" -co COMPRESS=DEFLATE \" + str(fn) + \" \" + str(output)\n",
    "    os.system(gdaltranString)\n",
    "    output = None\n",
    "\n",
    "#gdal_translate -of GTiff -b 10 input.nc output.tiff  # to get 10th band, it works fine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:18:12) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef1643838ba400d9e56910a4ebe1d7c2ddcc0867ba383b6e8e5b6e0b2b833d6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
